{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installer la bibliothèque Kaggle\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Téléverser votre fichier kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mv \"kaggle (1).json\" kaggle.json\n",
        "\n",
        "# Configurer Kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Télécharger le dataset \"Road Sign Detection\"\n",
        "!kaggle datasets download -d andrewmvd/road-sign-detection\n",
        "\n",
        "# Décompresser le fichier téléchargé\n",
        "!mkdir road_sign_detection\n",
        "!unzip road-sign-detection.zip -d road_sign_detection\n"
      ],
      "metadata": {
        "id": "tz1Rj5CBHvoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE5V7AxYzEA5"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio transformers pycocotools opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics tensorboard"
      ],
      "metadata": {
        "id": "I4O82Lgnl62Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym2DIhJezExh"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import albumentations as A\n",
        "import torchaudio\n",
        "from pycocotools.coco import COCO\n",
        "import cv2\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, T5TokenizerFast, T5ForConditionalGeneration\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "root_dir = '/content/road_sign_detection'\n",
        "images_dir = os.path.join(root_dir, 'images')\n",
        "annotations_dir = os.path.join(root_dir, 'annotations')\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "val_dir = os.path.join(root_dir, 'val')\n",
        "test_dir = os.path.join(root_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'annotations'), exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'annotations'), exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, 'annotations'), exist_ok=True)\n",
        "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png') or f.endswith('.jpg')])\n",
        "annotation_files = sorted([f for f in os.listdir(annotations_dir) if f.endswith('.xml')])\n",
        "train_images, test_images, train_annotations, test_annotations = train_test_split(\n",
        "    image_files, annotation_files, test_size=0.2, random_state=42, shuffle=False\n",
        ")\n",
        "\n",
        "val_images, test_images, val_annotations, test_annotations = train_test_split(\n",
        "    test_images, test_annotations, test_size=0.5, random_state=42, shuffle=False\n",
        ")\n",
        "\n",
        "def move_files(file_list, source_dir, dest_dir):\n",
        "    for file_name in file_list:\n",
        "        shutil.move(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))\n",
        "\n",
        "move_files(train_images, images_dir, os.path.join(train_dir, 'images'))\n",
        "move_files(train_annotations, annotations_dir, os.path.join(train_dir, 'annotations'))\n",
        "\n",
        "move_files(val_images, images_dir, os.path.join(val_dir, 'images'))\n",
        "move_files(val_annotations, annotations_dir, os.path.join(val_dir, 'annotations'))\n",
        "\n",
        "move_files(test_images, images_dir, os.path.join(test_dir, 'images'))\n",
        "move_files(test_annotations, annotations_dir, os.path.join(test_dir, 'annotations'))\n",
        "\n",
        "# Définir les noms de classe\n",
        "class_names = ['speedlimit', 'stop', 'crosswalk', 'trafficlight']\n",
        "\n",
        "# Créer le fichier de configuration des données\n",
        "data_yaml = \"\"\"\n",
        "train: /content/road_sign_detection/train/images\n",
        "val: /content/road_sign_detection/val/images\n",
        "\n",
        "nc: 4  # nombre de classes\n",
        "names: ['speedlimit', 'stop', 'crosswalk', 'trafficlight']\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/data.yaml', 'w') as f:\n",
        "    f.write(data_yaml)\n",
        "\n",
        "# Charger un modèle pré-entraîné YOLOv5s\n",
        "model = YOLO('yolov5s.pt')\n",
        "results = model.train(data='/content/data.yaml', epochs=50, imgsz=640, batch=32, project='runs/train', name='exp', exist_ok=True)\n",
        "results = model.val(data='/content/data.yaml')\n",
        "model.save('/content/road_sign_detection/best_model.pt')\n"
      ],
      "metadata": {
        "id": "RgdVUKhzRDDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "1jedHdvaHNBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train\n"
      ],
      "metadata": {
        "id": "CzQn1D_Orjt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts\n"
      ],
      "metadata": {
        "id": "E1ZOcQnhgDcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from gtts import gTTS\n",
        "import IPython.display as ipd\n",
        "\n",
        "model = YOLO('/content/road_sign_detection/best_model.pt')\n",
        "test_images_dir = '/content/road_sign_detection/test/images'\n",
        "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith('.png') or img.endswith('.jpg')]\n",
        "def generate_description(results):\n",
        "    descriptions = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            class_id = int(box.cls)\n",
        "            score = float(box.conf)\n",
        "            descriptions.append(f\"Detected {model.names[class_id]} with confidence {score:.2f}\")\n",
        "    return \" \".join(descriptions)\n",
        "def text_to_speech(text):\n",
        "    if text:\n",
        "        tts = gTTS(text=text, lang='en')\n",
        "        tts.save(\"output.mp3\")\n",
        "        ipd.display(ipd.Audio(\"output.mp3\"))\n",
        "    else:\n",
        "        print(\"No detections to speak about.\")\n",
        "for img_path in test_images:\n",
        "    results = model(img_path)\n",
        "    description = generate_description(results)\n",
        "    print(description)\n",
        "    text_to_speech(description)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    plt.imshow(img)\n",
        "    plt.title(description)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "dvWeT7gwiyfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "model = YOLO('/content/road_sign_detection/best_model.pt')\n",
        "test_images_dir = '/content/road_sign_detection/test/images'\n",
        "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith('.png') or img.endswith('.jpg')]\n",
        "for img_path in test_images:\n",
        "    results = model(img_path)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3hhPC3XpbhCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}